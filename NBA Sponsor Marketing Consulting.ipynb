{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conn_url = 'postgresql://postgres:123@localhost/APAN 5310 Final Project'\n",
    "engine = create_engine(conn_url)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#player\n",
    "all_seasons=pd.read_csv('all_seasons.csv')\n",
    "\n",
    "# Filter data from 2012 to 2020\n",
    "all_seasons12_20=all_seasons[all_seasons.season.isin(['2012-13','2013-14','2014-15','2015-16','2016-17','2017-18','2018-19','2019-20','2020-21'])]\n",
    "\n",
    "# Keep latest data of each player\n",
    "all_seasons12_20=all_seasons12_20.groupby('player_name').last()\n",
    "all_seasons12_20=all_seasons12_20.reset_index()\n",
    "\n",
    "# Lower case all the characters\n",
    "player_lower = all_seasons12_20['player_name'].str.lower()\n",
    "all_seasons12_20.insert(1, 'player_lower', player_lower)\n",
    "\n",
    "# Delete special characters in player names\n",
    "import re\n",
    "amatch = [re.sub(r'[^a-z]','',string) for string in all_seasons12_20.player_lower]\n",
    "all_seasons12_20.insert(2, 'player_match', amatch)\n",
    "\n",
    "# Add incrementing integers\n",
    "all_seasons12_20.insert(0, 'player_id', range(1, 1 + len(all_seasons12_20)))\n",
    "\n",
    "# Extract necessary columns for player table\n",
    "player_df=all_seasons12_20[['player_id','player_name','player_height','player_weight','draft_year','college','country']]\n",
    "\n",
    "# Adjusted column names according to schema\n",
    "player_df = player_df.rename(columns={\"player_height\": \"height\", \"player_weight\": \"weight\"})\n",
    "player_df.to_sql(name='player', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import teams dataset\n",
    "teams = pd.read_csv(\"teams.csv\")\n",
    "\n",
    "#We can  create a subset of df_teams corresponding to the teams database table.\n",
    "temp_teams_df= teams[['ABBREVIATION','YEARFOUNDED']]\n",
    "\n",
    "#delete duplicate values\n",
    "temp_teams_df=temp_teams_df.drop_duplicates()\n",
    "\n",
    "# insert team_id\n",
    "temp_teams_df.insert(0, 'team_id', range(1, 1 + len(temp_teams_df)))\n",
    "\n",
    "#rename the column name of dataframe to match the column name of table\n",
    "temp_teams_df = temp_teams_df.rename(columns={\"ABBREVIATION\": \"team_name\", \"YEARFOUNDED\": \"year_found\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load team data to the database\n",
    "temp_teams_df.to_sql(name='team', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#player_stats\n",
    "Player12_22=pd.read_csv('NBA Players 2012-2022.csv')\n",
    "\n",
    "# Filter data from 2012 to 2020\n",
    "Player12_20=Player12_22[Player12_22.year<2021]\n",
    "\n",
    "# Lower case player names\n",
    "player_lower = Player12_20['PLAYER'].str.lower()\n",
    "Player12_20.insert(2, 'player_lower', player_lower)\n",
    "\n",
    "# Delete special characters in player names\n",
    "import re\n",
    "pmatch = [re.sub(r'[^a-z]','',string) for string in Player12_20.PLAYER]\n",
    "Player12_20.insert(2, 'player_match', pmatch)\n",
    "temp_player_match=all_seasons12_20[['player_id','player_match']].drop_duplicates()\n",
    "\n",
    "# Match player names according to foundation player table\n",
    "match = [x for x in pmatch if x in amatch]\n",
    "Player12_20_match=Player12_20[Player12_20.player_match.isin(match)]\n",
    "temp_player=all_seasons12_20[['player_id','player_match']]\n",
    "\n",
    "# Map player_id\n",
    "player_id_list = [temp_player.player_id[temp_player.player_match == i].values[0] for i in Player12_20_match.player_match]\n",
    "\n",
    "# Add player_id into the main dataframe\n",
    "Player12_20_match.insert(1,'player_id',player_id_list)\n",
    "\n",
    "# Upper case team names for matching\n",
    "team_upper = Player12_20_match['TEAM'].str.upper()\n",
    "Player12_20_match.insert(5,'team_name',team_upper)\n",
    "\n",
    "# Adjust team name for matching\n",
    "Player12_20_match=Player12_20_match[Player12_20_match.team_name!='NJN']\n",
    "Player12_20_match=Player12_20_match.replace('BRO','BKN')\n",
    "Player12_20_match=Player12_20_match.replace('PHO','PHX')\n",
    "Player12_20_match=Player12_20_match.replace('GOL','GSW')\n",
    "Player12_20_match=Player12_20_match.replace('SAN','SAS')\n",
    "Player12_20_match=Player12_20_match.replace('NOR','NOP')\n",
    "\n",
    "# Map team_id\n",
    "team_id_list = [temp_teams_df.team_id[temp_teams_df.team_name == i].values[0] for i in Player12_20_match.team_name]\n",
    "Player12_20_match.insert(4, 'team_id', team_id_list)\n",
    "\n",
    "# Extract necessary columns for player_stats table\n",
    "temp_player_stat=Player12_20_match[['player_id','team_id','year','MPG','MIN%','USG%','TOr','SPG','FT%','2P%','3P%']]\n",
    "\n",
    "# Adjusted column names according to schema \n",
    "temp_player_stat = temp_player_stat.rename(columns={\"MPG\": \"mpg\", \"MIN%\": \"min_percentage\", \"USG%\": \"usage_percentage\", \"TOr\": \"turnover_percentage\", \"SPG\": \"steal_per_game\", \"FT%\": \"freethrow_percentage\", \"2P%\": \"two_point_percentage\", \"3P%\": \"three_point_percentage\"})\n",
    "temp_player_stat. \\\n",
    "    drop_duplicates().to_sql(name='player_stats', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load arena data\n",
    "arena = pd.read_csv(\"Team_Arena_Year.csv\")\n",
    "\n",
    "# create a temp dataframe with unique arena\n",
    "temp_arena_df = arena[['Arena Name','Location','Capacity']]\n",
    "\n",
    "#delete duplicate values.\n",
    "temp_arena_df=temp_arena_df.drop_duplicates()\n",
    "\n",
    "# insert arena_id\n",
    "temp_arena_df.insert(0, 'arena_id', range(1, 1 + len(temp_arena_df)))\n",
    "\n",
    "#rename the column name of dataframe to match the column name of table\n",
    "temp_arena_df = temp_arena_df.rename(columns={\"Arena Name\": \"arena_name\", \"Location\": \"arena_location\",\"Capacity\":\"capacity\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load arena data to the database\n",
    "temp_arena_df.to_sql(name='arena', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# team_arena\n",
    "\n",
    "#insert arena's arena_id by merging temp_arena dataframe and arena dataframe\n",
    "arena = pd.merge(arena, temp_arena_df, how = 'left',left_on = 'Arena Name',right_on = 'arena_name')\n",
    "\n",
    "# insert team_id by merging temp_teams_df with arena dataframe\n",
    "team_arena = pd.merge(arena, temp_teams_df,how = 'left',left_on = 'Team Name',right_on = 'team_name')\n",
    "\n",
    "team_arena = team_arena[['team_id','arena_id','Year']]\n",
    "team_arena=team_arena.rename(columns={\"Year\": \"year\"})\n",
    "team_arena[team_arena.isnull().values == True]\n",
    "team_arena = team_arena.fillna(value=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load team_arena data to the database\n",
    "team_arena.to_sql(name='team_arena', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-1-767da8eb83b5>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-767da8eb83b5>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# game \n",
    "\n",
    "#import game data\n",
    "games = pd.read_csv(\"games 1.csv\")\n",
    "games = games.loc[(games['SEASON']<2021) & (games['SEASON']>2011) ]\n",
    "\n",
    "#insert game_id\n",
    "games.insert(0, 'id', range(1, 1 + len(games)))\n",
    "\n",
    "temp_game_df = games[['id','GAME_DATE_EST','winner_team','winner_score']].drop_duplicates()\n",
    "\n",
    "#replace winner_team with team_id\n",
    "temp_teams_df.head()\n",
    "\n",
    "#insert winners' team_id by merging team dataframe and game dataframe\n",
    "result = pd.merge(temp_game_df, temp_teams_df, how = 'left',left_on = 'winner_team',right_on = 'team_name')\n",
    "\n",
    "temp_game_df = result[['id','GAME_DATE_EST','team_id','winner_score']].rename(columns={\"id\": \"game_id\", \"GAME_DATE_EST\": \"game_date\",\"team_id\": \"winner_id\"})\n",
    "                                                                                       \n",
    "                                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load game data to the database\n",
    "temp_game_df.to_sql(name='game', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# team_game \n",
    "#team_game's data\n",
    "team_game_temp = games[['id','home_team','visitor_team']].drop_duplicates()\n",
    "team_game_temp = pd.merge(team_game_temp, temp_teams_df, how = 'left',left_on = 'home_team',right_on = 'team_name')\n",
    "team_game_temp = team_game_temp[['id','visitor_team','team_id']].rename(columns={\"id\": \"game_id\",\"team_id\":\"home_team_id\"})\n",
    "team_game_temp = pd.merge(team_game_temp, temp_teams_df, how = 'left',left_on = 'visitor_team',right_on = 'team_name')\n",
    "team_game_temp = team_game_temp[['game_id','home_team_id','team_id']].rename(columns={\"team_id\":\"visitor_team_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load team_game data to database\n",
    "team_game_temp.to_sql(name='team_game', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranking\n",
    "ranking = pd.read_csv(\"ranking.csv\")\n",
    "#delete duplicate values\n",
    "ranking=ranking[['TEAM_ID','STANDINGSDATE','W']].drop_duplicates()\n",
    "#filter the ranking data from 2012-2020\n",
    "ranking = ranking.loc[(ranking['STANDINGSDATE'] == '2012-12-31')| (ranking['STANDINGSDATE'] == '2013-12-31') | (ranking['STANDINGSDATE'] == '2014-12-31') |\n",
    "                      (ranking['STANDINGSDATE'] == '2015-12-31') | (ranking['STANDINGSDATE'] == '2016-12-31')| (ranking['STANDINGSDATE'] == '2017-12-31')| \n",
    "                      (ranking['STANDINGSDATE'] == '2018-12-31') | (ranking['STANDINGSDATE'] == '2019-12-31') | (ranking['STANDINGSDATE'] == '2020-12-31')]\n",
    "import datetime\n",
    "ranking['STANDINGSDATE'] = pd.to_datetime(ranking['STANDINGSDATE'])\n",
    "ranking['STANDINGSDATE']=ranking['STANDINGSDATE'].apply(lambda x: x.year)\n",
    "ranking['ranking'] = ranking.groupby('STANDINGSDATE')['W'].rank(ascending=False,method='min')\n",
    "ranking = pd.merge(ranking, teams, how = 'left',left_on = 'TEAM_ID',right_on = 'TEAM_ID')\n",
    "ranking = pd.merge(ranking, temp_teams_df, how = 'left',left_on = 'ABBREVIATION',right_on = 'team_name')\n",
    "temp_ranking_df = ranking[['team_id','STANDINGSDATE','ranking']].rename(columns = {\"STANDINGSDATE\":\"year\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ranking data to dataframes\n",
    "temp_ranking_df.to_sql(name='ranking', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_star\n",
    "\n",
    "# Extract necessary data for all-star table\n",
    "all_star=Player12_20_match[['player_id','year','all_star']]\n",
    "\n",
    "# Filter all-star players\n",
    "all_star=all_star[all_star.all_star==1]\n",
    "\n",
    "# Push data into database\n",
    "all_star[['player_id','year']].drop_duplicates().to_sql(name='all_star', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load game_id data\n",
    "game = pd.read_csv(\"games_id.csv\")\n",
    "temp_game_df = game[['id','GAME_DATE_EST','winner_team','winner_score']].drop_duplicates()\n",
    "#insert winners' team_id by merging team dataframe and game dataframe\n",
    "result = pd.merge(temp_game_df, temp_teams_df, how = 'left',left_on = 'winner_team',right_on = 'team_name')\n",
    "temp_game_df = result[['id','GAME_DATE_EST','team_id','winner_score']].rename(columns={\"id\": \"game_id\", \"GAME_DATE_EST\": \"game_date\",\"team_id\":\"winner_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#player_game\n",
    "games=pd.read_csv('games_details.csv')\n",
    "\n",
    "# Lower case player names\n",
    "player_lower3 = games['PLAYER_NAME'].str.lower()\n",
    "games.insert(6,'player_lower',player_lower3)\n",
    "\n",
    "# Delete special characters in player names\n",
    "import re\n",
    "gmatch = [re.sub(r'[^a-z]','',string) for string in games.player_lower]\n",
    "games.insert(7,'player_match',gmatch)\n",
    "\n",
    "# Match games based on game table\n",
    "match3 = [x for x in gmatch if x in amatch]\n",
    "games=games[games.GAME_ID.isin(game.GAME_ID)]\n",
    "games_match=games[games.player_match.isin(match3)]\n",
    "\n",
    "# Map player_id list\n",
    "player_id_list3 = [temp_player.player_id[temp_player.player_match == i].values[0] for i in games_match.player_match]\n",
    "games_match.insert(5,'player_id',player_id_list3)\n",
    "\n",
    "# Map game_id list\n",
    "game_id_list = [game.id[game.GAME_ID == i].values[0] for i in games_match.GAME_ID]\n",
    "games_match.insert(0,'game_id',game_id_list)\n",
    "\n",
    "# Extract necessary columns for player_game table\n",
    "temp_player_game=games_match[['player_id','game_id','MIN','START_POSITION','PTS','TO','STL']]\n",
    "\n",
    "# Adjust column names according to schema\n",
    "temp_player_game = temp_player_game.rename(columns={\"MIN\": \"minute\", \"START_POSITION\": \"position\", \"PTS\": \"points_scored\", \"TO\": \"turnover\", \"STL\": \"steal\"})\n",
    "\n",
    "# Keep latest data for each player in each game (solve redundancy)\n",
    "temp_player_game=temp_player_game.groupby(['player_id','game_id']).last()\n",
    "temp_player_game=temp_player_game.reset_index()\n",
    "\n",
    "# Push data into database\n",
    "temp_player_game[['player_id','game_id','position','points_scored','turnover','steal']].\\\n",
    "    drop_duplicates().to_sql(name='player_game', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### company table \n",
    "\n",
    "### load company data and clean it \n",
    "df2 = pd.read_csv(\"Team Sponsors2.csv\")\n",
    "df2 = df2.rename(columns={'Previous jersey sponsor(s)': 'company_name'})\n",
    "df_company = df2.company_name.str.split(',').apply(pd.Series, 1).stack()\n",
    "df_company.index = df_company.index.droplevel(-1)\n",
    "df_company.name = 'company_name'\n",
    "del df2['company_name']\n",
    "df2 = df2.join(df_company);df2\n",
    "df2.insert(0, 'company_id', range(1, 1 + len(df2)))\n",
    "df2['company_name'] = df2['company_name'].str.slice(0,-11)\n",
    "company = df2[['company_id','company_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert company data into SQL\n",
    "for rows in company.itertuples():\n",
    "    connection.execute('''\n",
    "                INSERT INTO company\n",
    "                VALUES (%s,%s);\n",
    "                ''',\n",
    "                rows.company_id,\n",
    "                rows.company_name\n",
    "                )\n",
    "table2= connection.execute('''select * from company;''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## team_company\n",
    "\n",
    "### read team_company data and clean it \n",
    "df3 = pd.read_csv(\"team_company.csv\")\n",
    "df3 = df3.rename(columns={'year ': 'year'})\n",
    "team_company= df3[['team_id','year','company_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert team_company data into SQL\n",
    "for rows in team_company.itertuples():\n",
    "    connection.execute('''\n",
    "                INSERT INTO team_company\n",
    "                VALUES (%s,%s,%s);\n",
    "                ''',\n",
    "                rows.team_id,\n",
    "                rows.year,\n",
    "                rows.company_id\n",
    "                )\n",
    "table_team_company= connection.execute('''select * from team_company;''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
